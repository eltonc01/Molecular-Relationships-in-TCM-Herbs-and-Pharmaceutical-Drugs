{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15ac655",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score\n",
    "from sklearn.model_selection import train_test_split,\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from IPython.utils import io\n",
    "import time\n",
    "from sklearn.model_selection import KFold, StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5acb79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain datasets\n",
    "\n",
    "df_proteins = pd.read_csv('protein descriptors pydpi.csv')\n",
    "df_drugs = pd.read_csv('drugbank drugs mordred + ECFP6 dropped columns.csv')\n",
    "df_dpi = pd.read_csv('all drugbank targets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d23c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain positive combos\n",
    "\n",
    "all_combos = []\n",
    "for r in range(0, len(df_dpi)):\n",
    "    ids = df_dpi.loc[r, 'Drug IDs'].split('; ')\n",
    "    protein = df_dpi.loc[r, 'STRING']\n",
    "    for i in ids:\n",
    "        all_combos.append([i, protein])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de26f8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = df_proteins.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebf8330",
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_index = {}\n",
    "for r in range(0, len(df_drugs)):\n",
    "    items = df_drugs.loc[r, 'IDs']\n",
    "    drug_index[items] = r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9aabd2b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# set unseen drug set\n",
    "\n",
    "val_drugspace = random.sample(list(set(drug_names)), 1000)\n",
    "\n",
    "drugset = []\n",
    "targetset = []\n",
    "out = []\n",
    "for i in all_combos:\n",
    "    drug = i[0]\n",
    "    if drug not in val_drugspace:\n",
    "        continue\n",
    "    protein = i[1]\n",
    "    try:\n",
    "        drug_index[drug]\n",
    "    except:\n",
    "        continue\n",
    "    if protein not in targets:\n",
    "        print(protein)\n",
    "        continue\n",
    "    drugset.append(drug)\n",
    "    targetset.append(protein)\n",
    "    out.append(1)\n",
    "    \n",
    "count = len(drugset) * 2\n",
    "while len(drugset) < count:\n",
    "    if len(drugset) % 1000 == 0:\n",
    "        print(len(drugset))\n",
    "    try:\n",
    "        d1 = random.choice(val_drugspace)\n",
    "        t1 = random.choice(target_names)\n",
    "        if t1 not in repeats[d1]:\n",
    "            drugset.append(d1)\n",
    "            targetset.append(t1)\n",
    "            out.append(0)\n",
    "        else:\n",
    "            continue\n",
    "    except:\n",
    "        continue\n",
    "    \n",
    "table = []\n",
    "table1 = ()\n",
    "for r in range(0, len(drugset)):\n",
    "    if r % 500 == 0:\n",
    "        print(r)\n",
    "    if r % 5000 == 0:\n",
    "        table1 = table1 + tuple(table)\n",
    "        table = []\n",
    "    try:\n",
    "        index1 = drug_index[drugset[r]]\n",
    "    except:\n",
    "        print('drug not found')\n",
    "        continue\n",
    "    row1 = df_drugs.loc[index1].drop('IDs').to_list()\n",
    "    try:\n",
    "        row2 = df_proteins[targetset[r]].to_list()\n",
    "    except:\n",
    "        print('protein not found')\n",
    "        continue\n",
    "    row = row1 + row2\n",
    "    table.append(tuple(row))\n",
    "table1 = table1 + tuple(table)\n",
    "\n",
    "del table\n",
    "    \n",
    "headers = df_drugs.columns.drop('IDs').to_list() + df_proteins['IDs'].to_list()\n",
    "headers = [str(x) for x in headers]\n",
    "val_set = pd.DataFrame(table1, columns=headers)\n",
    "val_results = out\n",
    "\n",
    "del table1\n",
    "\n",
    "drop = []\n",
    "for i in val_set.columns:\n",
    "    if i not in df.columns.to_list()[2:]:\n",
    "        drop.append(i)\n",
    "        \n",
    "val_set = val_set.drop(columns=drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088997e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "drugset = []\n",
    "targetset = []\n",
    "out = []\n",
    "for i in all_combos:\n",
    "    drug = i[0]\n",
    "    if drug in val_drugspace:\n",
    "        continue\n",
    "    protein = i[1]\n",
    "    try:\n",
    "        drug_index[drug]\n",
    "    except:\n",
    "        continue\n",
    "    if protein not in targets:\n",
    "        print(protein)\n",
    "        continue\n",
    "    drugset.append(drug)\n",
    "    targetset.append(protein)\n",
    "    out.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7021eae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_names = drugset\n",
    "drug_names = list(set(drug_names))\n",
    "target_names = targetset\n",
    "target_names = list(set(target_names))\n",
    "print(f'Drug count: {len(drug_names)}, Target cound: {len(target_names)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868b7774",
   "metadata": {},
   "outputs": [],
   "source": [
    "repeats = {}\n",
    "for i in all_combos:\n",
    "    repeats[i[0]] = []\n",
    "for i in all_combos:\n",
    "    repeats[i[0]].append(i[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aac59fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = len(drugset) * 2\n",
    "while len(drugset) < count:\n",
    "    if len(drugset) % 1000 == 0:\n",
    "        print(len(drugset))\n",
    "    try:\n",
    "        d1 = random.choice(drug_names)\n",
    "        t1 = random.choice(target_names)\n",
    "        if t1 not in repeats[d1]:\n",
    "            drugset.append(d1)\n",
    "            targetset.append(t1)\n",
    "            out.append(0)\n",
    "        else:\n",
    "            continue\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1dc7717",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# construct dataset\n",
    "\n",
    "table = []\n",
    "table1 = ()\n",
    "for r in range(0, len(drugset)):\n",
    "    if r % 500 == 0:\n",
    "        print(r)\n",
    "    if r % 5000 == 0:\n",
    "        table1 = table1 + tuple(table)\n",
    "        table = []\n",
    "    try:\n",
    "        index1 = drug_index[drugset[r]]\n",
    "    except:\n",
    "        print('drug not found')\n",
    "        continue\n",
    "    row1 = df_drugs.loc[index1].drop('IDs').to_list()\n",
    "    try:\n",
    "        row2 = df_proteins[targetset[r]].to_list()\n",
    "    except:\n",
    "        print('protein not found')\n",
    "        continue\n",
    "    row = row1 + row2\n",
    "    table.append(tuple(row))\n",
    "table1 = table1 + tuple(table)\n",
    "\n",
    "del table\n",
    "    \n",
    "headers = df_drugs.columns.drop('IDs').to_list() + df_proteins['IDs'].to_list()\n",
    "headers = [str(x) for x in headers]\n",
    "file = pd.DataFrame(table1, columns=headers)\n",
    "\n",
    "drop = []\n",
    "for i in file.columns:\n",
    "    if i not in df.columns.to_list()[2:]:\n",
    "        drop.append(i)\n",
    "        \n",
    "file = file.drop(columns=drop)\n",
    "results = out\n",
    "\n",
    "del table1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9652872",
   "metadata": {},
   "outputs": [],
   "source": [
    "file.insert(0, 'Binding', out)\n",
    "file = pd.DataFrame(file, columns=['Binding'], df_drugs.columns.to_list()[1:] + df_proteins.columns.to_list()[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ccf7202",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "x = file.drop(columns=['Binding', 'Combination'])\n",
    "y = file['Binding']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53cd14c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db41127",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = joblib.save(scaler, 'scaler.save')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0536b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow_addons as tfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f641018",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5909de86",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "n_cols = x_train.shape[1]\n",
    "model.add(Dense(n_cols + 1, activation='relu', input_shape=(n_cols,)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(n_cols / 2, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2, activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5dc6012",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.001), \n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "             metrics=[tf.keras.metrics.AUC(), tfa.metrics.F1Score(num_classes=2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3514a1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_monitor = EarlyStopping(patience=3)\n",
    "model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=50, batch_size = 32, callbacks=[early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1dfb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp scaling code obtained here: https://sourajit16-02-93.medium.com/neural-network-calibration-46997f8c872c\n",
    "\n",
    "temp = tf.Variable(initial_value=1.0, trainable=True)\n",
    "\n",
    "def compute_loss():\n",
    "    y_pred_model_w_temp = tf.math.divide(y_pred, temp)\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(tf.convert_to_tensor(y_test), y_pred_model_w_temp))\n",
    "    return loss\n",
    "\n",
    "optimizer = tf.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "print('Temperature Initial value: {}'.format(temp.numpy()))\n",
    "\n",
    "for i in range(300):\n",
    "     opts = optimizer.minimize(compute_loss, var_list=[temp])\n",
    "        \n",
    "print('Temperature Final value: {}'.format(temp.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5fc0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 fold cross validaiton\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80649609",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "df = shuffle(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bacc891",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = np.array(df.drop(columns=['Combination', 'Synergy']))\n",
    "results = np.array(df['Synergy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e019e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score, multilabel_confusion_matrix, f1_score, confusion_matrix, accuracy_score, roc_auc_score, precision_score, recall_score, average_precision_score, roc_curve, auc, precision_recall_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab0633f",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = []\n",
    "roc = []\n",
    "prc = []\n",
    "prec = []\n",
    "f1 = []\n",
    "rec = []\n",
    "spec = []\n",
    "curve = []\n",
    "prc_curve = []\n",
    "models = {}\n",
    "scalers = {}\n",
    "test_sets = {}\n",
    "test_results = {}\n",
    "iteration = 0\n",
    "\n",
    "for train, val in kf.split(file, results):\n",
    "    iteration += 1\n",
    "    x_train = file[train]\n",
    "    y_train = to_categorical(results[train])\n",
    "    x_val = file[val]\n",
    "    y_val = results[val]\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    x_train = scaler.fit_transform(x_train).astype('float32')\n",
    "    x_val = scaler.transform(x_val).astype('float32')\n",
    "    \n",
    "    model = Sequential()\n",
    "    n_cols = x_train.shape[1]\n",
    "    model.add(Dense(n_cols + 1, activation='relu', input_shape=(n_cols,)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(n_cols / 2, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    model.add(Temperature())\n",
    "    \n",
    "    model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.001), \n",
    "              loss='categorical_crossentropy',\n",
    "             metrics=[tf.keras.metrics.AUC(), tfa.metrics.F1Score(num_classes=2)])\n",
    "    \n",
    "    early_stopping_monitor = EarlyStopping(patience=3)\n",
    "    model.fit(x_train, y_train, validation_split=0.2, epochs=50, batch_size = 32, callbacks=[early_stopping_monitor])\n",
    "    \n",
    "    predictions = model.predict(x_val)\n",
    "    \n",
    "    binary_pred = []\n",
    "    for i in predictions:\n",
    "        if i[0] > i[1]:\n",
    "            binary_pred.append(0)\n",
    "        else:\n",
    "            binary_pred.append(1)\n",
    "            \n",
    "    acc.append(accuracy_score(y_val, binary_pred))\n",
    "    roc.append(roc_auc_score(y_val, binary_pred))\n",
    "    prc.append(average_precision_score(y_val, binary_pred))\n",
    "    f1.append(f1_score(y_val, binary_pred))\n",
    "    rec.append(recall_score(y_val, binary_pred))\n",
    "    prec.append(precision_score(y_val, binary_pred))\n",
    "    spec.append(recall_score(y_val, binary_pred, pos_label=0))\n",
    "    \n",
    "    print(roc_auc_score(y_val, binary_pred))\n",
    "    \n",
    "    fpr, tpr, thresholds = roc_curve(y_val, predictions[:,1])\n",
    "    curve.append([fpr, tpr, thresholds])\n",
    "    precision, recall, thresholds = precision_recall_curve(y_val, predictions[:,1])\n",
    "    prc_curve.append([precision, recall, thresholds])\n",
    "    \n",
    "    models[f'model{iteration}'] = model\n",
    "    scalers[f'scaler{iteration}'] = scaler\n",
    "    test_sets[f'set{iteration}'] = x_val\n",
    "    test_results[f'set{iteration}'] = y_val"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
